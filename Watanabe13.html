<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Achievability of Asymptotic Minimax Regret in Online and Batch Prediction | ACML 2013 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Achievability of Asymptotic Minimax Regret in Online and Batch Prediction">

  <meta name="citation_author" content="Watanabe, Kazuho">

  <meta name="citation_author" content="Roos, Teemu">

  <meta name="citation_author" content="Myllymäki, Petri">

<meta name="citation_publication_date" content="2013">
<meta name="citation_conference_title" content="Asian Conference on Machine Learning">
<meta name="citation_firstpage" content="181">
<meta name="citation_lastpage" content="196">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v29/Watanabe13.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Achievability of Asymptotic Minimax Regret in Online and Batch Prediction</h1>

	<div id="authors">
	
		Kazuho Watanabe,
	
		Teemu Roos,
	
		Petri Myllymäki
	</div>;
	<div id="info">
		JMLR W&amp;CP 29 
		
		: 
		181–196, 2013
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		The normalized maximum likelihood model achieves the minimax coding (log-loss) regret for data of fixed sample size <span class="math">\(n\)</span>. However, it is a batch strategy, i.e., it requires that <span class="math">\(n\)</span> be known in advance. Furthermore, it is computationally infeasible for most statistical models, and several computationally feasible alternative strategies have been devised. We characterize the achievability of asymptotic minimaxity by batch strategies (i.e., strategies that depend on <span class="math">\(n\)</span>) as well as online strategies (i.e., strategies independent of <span class="math">\(n\)</span>). On one hand, we conjecture that for a large class of models, no online strategy can be asymptotically minimax. We prove that this holds under a slightly stronger definition of asymptotic minimaxity. Our numerical experiments support the conjecture about non-achievability by so called last-step minimax algorithms, which are independent of <span class="math">\(n\)</span>. On the other hand, we show that in the multinomial model, a Bayes mixture defined by the conjugate Dirichlet prior with a simple dependency on <span class="math">\(n\)</span> achieves asymptotic minimaxity for all sequences, thus providing a simpler asymptotic minimax strategy compared to earlier work by Xie and Barron. The numerical results also demonstrate superior finite-sample behavior by a number of novel batch and online algorithms.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="http://jmlr.org/proceedings/papers/v29/Watanabe13.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
