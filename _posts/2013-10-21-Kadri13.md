---
pdf: http://proceedings.mlr.press/v29/Kadri13.pdf
title: The Multi-Task Learning View of Multimodal Data
abstract: We study the problem of learning from multiple views using kernel methods
  in a supervised setting.  We approach this  problem from a multi-task learning point
  of view and illustrate how to capture the interesting multimodal structure of the
  data using multi-task kernels.  Our analysis shows that the multi-task perspective
  offers the flexibility to design more efficient multiple-source learning algorithms,
  and hence the ability to exploit multiple descriptions of the data. In particular,
  we formulate the multimodal learning framework using vector-valued reproducing kernel
  Hilbert spaces, and we derive specific multi-task kernels that can operate over
  multiple modalities. Finally,  we analyze the vector-valued regularized least squares
  algorithm in this context, and demonstrate its potential in a series of experiments
  with a real-world multimodal data set.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Kadri13
month: 0
tex_title: The Multi-Task Learning View of Multimodal Data
firstpage: 261
lastpage: 276
page: 261-276
order: 261
cycles: false
author:
- given: Hachem
  family: Kadri
- given: Stephane
  family: Ayache
- given: Cécile
  family: Capponi
- given: Sokol
  family: Koço
- given: François-Xavier
  family: Dupé
- given: Emilie
  family: Morvant
date: 2013-10-21
address: Australian National University, Canberra, Australia
publisher: PMLR
container-title: Proceedings of the 5th Asian Conference on Machine Learning
volume: '29'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 10
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
