---
pdf: http://proceedings.mlr.press/v29/Komiyama13/Komiyama13.pdf
title: Multi-armed Bandit Problem with Lock-up Periods
abstract: We investigate a stochastic multi-armed bandit problem in which the forecasterâ€™s
  choice is restricted. In this problem, rounds are divided into lock-up periods and
  the forecaster must select the same arm throughout a period. While there has been
  much work on finding optimal algorithms for the stochastic multi-armed bandit problem,  their
  use under restricted conditions is not obvious. We extend the application ranges
  of these algorithms by proposing their natural conversion from ones for the stochastic
  bandit problem (index-based algorithms and greedy algorithms) to ones for the multi-armed
  bandit problem with lock-up periods. We prove that the regret of the converted algorithms
  is O(\logT + L_max ), where T is the total number of rounds and L_max is the maximum
  size of the lock-up periods. The regret is preferable, except for the case when
  the maximum size of the lock-up periods is large. For these cases, we propose a
  meta-algorithm that results in a smaller regret by using a empirical best arm for
  large periods. We empirically compare and discuss these algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Komiyama13
month: 0
firstpage: 100
lastpage: 115
page: 100-115
sections: 
author:
- given: Junpei
  family: Komiyama
- given: Issei
  family: Sato
- given: Hiroshi
  family: Nakagawa
date: 2013-10-21
address: Australian National University, Canberra, Australia
publisher: PMLR
container-title: Proceedings of the 5th Asian Conference on Machine Learning
volume: '29'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 10
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
