<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Polynomial Runtime Bounds for Fixed-Rank Unsupervised Least-Squares Classification | ACML 2013 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Polynomial Runtime Bounds for Fixed-Rank Unsupervised Least-Squares Classification">

  <meta name="citation_author" content="Gieseke, Fabian">

  <meta name="citation_author" content="Pahikkala, Tapio">

  <meta name="citation_author" content="Igel, Christian">

<meta name="citation_publication_date" content="2013">
<meta name="citation_conference_title" content="Asian Conference on Machine Learning">
<meta name="citation_firstpage" content="62">
<meta name="citation_lastpage" content="71">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v29/Gieseke13.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Polynomial Runtime Bounds for Fixed-Rank Unsupervised Least-Squares Classification</h1>

	<div id="authors">
	
		Fabian Gieseke,
	
		Tapio Pahikkala,
	
		Christian Igel
	</div>;
	<div id="info">
		JMLR W&amp;CP 29 
		
		: 
		62â€“71, 2013
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Maximum margin clustering can be regarded as the direct extension of support vector machines to unsupervised learning scenarios. The goal is to partition unlabeled data into two classes such that a subsequent application of a support vector machine would yield the overall best result (with respect to the optimization problem associated with support vector machines). While being very appealing from a conceptual point of view, the combinatorial nature of the induced optimization problem renders a direct application of this concept difficult. In order to obtain efficient optimization schemes, various surrogates of the original problem definition have been proposed in the literature. In this work, we consider one of these variants, called unsupervised regularized least-squares classification, which is based on the square loss, and develop polynomial upper runtime bounds for the induced combinatorial optimization task. In particular, we show that for <span class="math">\(n\)</span> patterns and kernel matrix of fixed rank <span class="math">\(r\)</span> (with given eigendecomposition), one can obtain an optimal solution in <span class="math">\(\mathcal{O}(n^{r})\)</span> time for <span class="math">\(r \leq 2\)</span> and in <span class="math">\(\mathcal{O}(n^{r-1})\)</span> time for <span class="math">\(r\geq 3\)</span>. The algorithmic framework is based on an interesting connection to the field of quadratic zero-one programming and permits the computation of exact solutions for the more general case of non-linear kernel functions in polynomial time.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="http://jmlr.org/proceedings/papers/v29/Gieseke13.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
